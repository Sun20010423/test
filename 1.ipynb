{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:49:16.508284Z",
     "start_time": "2024-11-05T04:48:53.672251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 你的路径\n",
    "train_path = Path('python/python/final/jsonl/train/')\n",
    "test_path = Path('python/python/final/jsonl/test/')\n",
    "valid_path = Path('python/python/final/jsonl/valid/')\n",
    "\n",
    "# 列名\n",
    "columns_long_list = ['repo', 'path', 'url', 'code', \n",
    "                     'code_tokens', 'docstring', 'docstring_tokens', \n",
    "                     'language', 'partition']\n",
    "\n",
    "# 函数来加载 .jsonl.gz 文件到 DataFrame\n",
    "def jsonl_list_to_dataframe(file_list, columns=columns_long_list):\n",
    "    \"\"\"Load a list of jsonl.gz files into a pandas DataFrame.\"\"\"\n",
    "    return pd.concat([pd.read_json(f, \n",
    "                                   orient='records', \n",
    "                                   compression='gzip',\n",
    "                                   lines=True)[columns] \n",
    "                      for f in file_list], sort=False)\n",
    "\n",
    "# 查找所有 .gz 文件\n",
    "train_files = sorted(train_path.glob('**/*.gz'))\n",
    "test_files = sorted(test_path.glob('**/*.gz'))\n",
    "valid_files = sorted(valid_path.glob('**/*.gz'))\n",
    "\n",
    "# 加载训练集、测试集、验证集\n",
    "train_df = jsonl_list_to_dataframe(train_files)\n",
    "test_df = jsonl_list_to_dataframe(test_files)\n",
    "valid_df = jsonl_list_to_dataframe(valid_files)\n",
    "\n",
    "# 筛选包含 `if` 条件的代码\n",
    "def filter_if_statements(df):\n",
    "    \"\"\"Filter DataFrame to only include samples with 'if' statements in the code.\"\"\"\n",
    "    return df[df['code'].str.contains(r'\\bif\\b')]\n",
    "\n",
    "# 筛选出包含 `if` 语句的代码\n",
    "train_if_df = filter_if_statements(train_df)\n",
    "\n",
    "# 保留训练集前 150,000 条作为预训练数据集\n",
    "pretrain_data = train_if_df.iloc[:150000]\n",
    "\n",
    "# 后 50,000 条作为微调数据集\n",
    "finetune_data = train_if_df.iloc[150000:200000]\n",
    "\n",
    "# 将微调数据集划分为训练、验证、测试集\n",
    "# 80% 作为微调训练数据，10% 作为验证集，10% 作为测试集\n",
    "train_finetune_data = finetune_data.iloc[:40000]  # 80% 训练集\n",
    "valid_finetune_data = finetune_data.iloc[40000:45000]  # 10% 验证集\n",
    "test_finetune_data = finetune_data.iloc[45000:]  # 10% 测试集\n",
    "\n",
    "# 检查数据集划分\n",
    "print(\"Pretrain Data: \", pretrain_data.shape)\n",
    "print(\"Finetune Train Data: \", train_finetune_data.shape)\n",
    "print(\"Finetune Valid Data: \", valid_finetune_data.shape)\n",
    "print(\"Finetune Test Data: \", test_finetune_data.shape)\n"
   ],
   "id": "ee01fbc63b839434",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain Data:  (150000, 9)\n",
      "Finetune Train Data:  (40000, 9)\n",
      "Finetune Valid Data:  (5000, 9)\n",
      "Finetune Test Data:  (5000, 9)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:49:16.524285Z",
     "start_time": "2024-11-05T04:49:16.515284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Train files:\", train_files)\n",
    "print(\"Test files:\", test_files)\n",
    "print(\"Valid files:\", valid_files)\n"
   ],
   "id": "8cbdf1a998a0d088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: [WindowsPath('python/python/final/jsonl/train/python_train_0.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_1.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_10.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_11.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_12.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_13.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_2.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_3.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_4.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_5.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_6.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_7.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_8.jsonl.gz'), WindowsPath('python/python/final/jsonl/train/python_train_9.jsonl.gz')]\n",
      "Test files: [WindowsPath('python/python/final/jsonl/test/python_test_0.jsonl.gz')]\n",
      "Valid files: [WindowsPath('python/python/final/jsonl/valid/python_valid_0.jsonl.gz')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:49:16.603822Z",
     "start_time": "2024-11-05T04:49:16.589297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_finetune_data"
   ],
   "id": "1216d9290d87a4c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                         repo                             path  \\\n",
       "18237        sffjunkie/astral                    src/astral.py   \n",
       "18239        sffjunkie/astral                    src/astral.py   \n",
       "18240        sffjunkie/astral                    src/astral.py   \n",
       "18241        sffjunkie/astral                    src/astral.py   \n",
       "18242        sffjunkie/astral                    src/astral.py   \n",
       "...                       ...                              ...   \n",
       "25974  bitcaster-io/bitcaster  src/bitcaster/config/environ.py   \n",
       "25975  bitcaster-io/bitcaster   src/bitcaster/utils/reflect.py   \n",
       "25976  bitcaster-io/bitcaster             src/bitcaster/otp.py   \n",
       "25977  bitcaster-io/bitcaster             src/bitcaster/otp.py   \n",
       "25978  bitcaster-io/bitcaster  src/bitcaster/utils/language.py   \n",
       "\n",
       "                                                     url  \\\n",
       "18237  https://github.com/sffjunkie/astral/blob/b0aa6...   \n",
       "18239  https://github.com/sffjunkie/astral/blob/b0aa6...   \n",
       "18240  https://github.com/sffjunkie/astral/blob/b0aa6...   \n",
       "18241  https://github.com/sffjunkie/astral/blob/b0aa6...   \n",
       "18242  https://github.com/sffjunkie/astral/blob/b0aa6...   \n",
       "...                                                  ...   \n",
       "25974  https://github.com/bitcaster-io/bitcaster/blob...   \n",
       "25975  https://github.com/bitcaster-io/bitcaster/blob...   \n",
       "25976  https://github.com/bitcaster-io/bitcaster/blob...   \n",
       "25977  https://github.com/bitcaster-io/bitcaster/blob...   \n",
       "25978  https://github.com/bitcaster-io/bitcaster/blob...   \n",
       "\n",
       "                                                    code  \\\n",
       "18237  def _get_elevation(self, location):\\n        \"...   \n",
       "18239  def dawn_utc(self, date, latitude, longitude, ...   \n",
       "18240  def sunrise_utc(self, date, latitude, longitud...   \n",
       "18241  def solar_noon_utc(self, date, longitude):\\n  ...   \n",
       "18242  def sunset_utc(self, date, latitude, longitude...   \n",
       "...                                                  ...   \n",
       "25974  def get_value(self, var, cast=None, default=en...   \n",
       "25975  def fqn(o):\\n    \"\"\"Returns the fully qualifie...   \n",
       "25976  def get_otp(self, message_list):\\n        \"\"\"\\...   \n",
       "25977  def validate(self, cipher_text, max_timedelta=...   \n",
       "25978  def get_attr(obj, attr, default=None):\\n    \"\"...   \n",
       "\n",
       "                                             code_tokens  \\\n",
       "18237  [def, _get_elevation, (, self, ,, location, ),...   \n",
       "18239  [def, dawn_utc, (, self, ,, date, ,, latitude,...   \n",
       "18240  [def, sunrise_utc, (, self, ,, date, ,, latitu...   \n",
       "18241  [def, solar_noon_utc, (, self, ,, date, ,, lon...   \n",
       "18242  [def, sunset_utc, (, self, ,, date, ,, latitud...   \n",
       "...                                                  ...   \n",
       "25974  [def, get_value, (, self, ,, var, ,, cast, =, ...   \n",
       "25975  [def, fqn, (, o, ), :, parts, =, [, ], if, isi...   \n",
       "25976  [def, get_otp, (, self, ,, message_list, ), :,...   \n",
       "25977  [def, validate, (, self, ,, cipher_text, ,, ma...   \n",
       "25978  [def, get_attr, (, obj, ,, attr, ,, default, =...   \n",
       "\n",
       "                                               docstring  \\\n",
       "18237  Query the elevation information with the latit...   \n",
       "18239  Calculate dawn time in the UTC timezone.\\n\\n  ...   \n",
       "18240  Calculate sunrise time in the UTC timezone.\\n\\...   \n",
       "18241  Calculate solar noon time in the UTC timezone....   \n",
       "18242  Calculate sunset time in the UTC timezone.\\n\\n...   \n",
       "...                                                  ...   \n",
       "25974  Return value for given environment variable.\\n...   \n",
       "25975  Returns the fully qualified class name of an o...   \n",
       "25976  Generates a url-safe base64 encoded encypted m...   \n",
       "25977  Will decrypt the url safe base64 encoded crypt...   \n",
       "25978  Recursive get object's attribute. May use dot ...   \n",
       "\n",
       "                                        docstring_tokens language partition  \n",
       "18237  [Query, the, elevation, information, with, the...   python     train  \n",
       "18239  [Calculate, dawn, time, in, the, UTC, timezone...   python     train  \n",
       "18240  [Calculate, sunrise, time, in, the, UTC, timez...   python     train  \n",
       "18241  [Calculate, solar, noon, time, in, the, UTC, t...   python     train  \n",
       "18242  [Calculate, sunset, time, in, the, UTC, timezo...   python     train  \n",
       "...                                                  ...      ...       ...  \n",
       "25974  [Return, value, for, given, environment, varia...   python     train  \n",
       "25975  [Returns, the, fully, qualified, class, name, ...   python     train  \n",
       "25976  [Generates, a, url, -, safe, base64, encoded, ...   python     train  \n",
       "25977  [Will, decrypt, the, url, safe, base64, encode...   python     train  \n",
       "25978  [Recursive, get, object, s, attribute, ., May,...   python     train  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18237</th>\n",
       "      <td>sffjunkie/astral</td>\n",
       "      <td>src/astral.py</td>\n",
       "      <td>https://github.com/sffjunkie/astral/blob/b0aa6...</td>\n",
       "      <td>def _get_elevation(self, location):\\n        \"...</td>\n",
       "      <td>[def, _get_elevation, (, self, ,, location, ),...</td>\n",
       "      <td>Query the elevation information with the latit...</td>\n",
       "      <td>[Query, the, elevation, information, with, the...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18239</th>\n",
       "      <td>sffjunkie/astral</td>\n",
       "      <td>src/astral.py</td>\n",
       "      <td>https://github.com/sffjunkie/astral/blob/b0aa6...</td>\n",
       "      <td>def dawn_utc(self, date, latitude, longitude, ...</td>\n",
       "      <td>[def, dawn_utc, (, self, ,, date, ,, latitude,...</td>\n",
       "      <td>Calculate dawn time in the UTC timezone.\\n\\n  ...</td>\n",
       "      <td>[Calculate, dawn, time, in, the, UTC, timezone...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18240</th>\n",
       "      <td>sffjunkie/astral</td>\n",
       "      <td>src/astral.py</td>\n",
       "      <td>https://github.com/sffjunkie/astral/blob/b0aa6...</td>\n",
       "      <td>def sunrise_utc(self, date, latitude, longitud...</td>\n",
       "      <td>[def, sunrise_utc, (, self, ,, date, ,, latitu...</td>\n",
       "      <td>Calculate sunrise time in the UTC timezone.\\n\\...</td>\n",
       "      <td>[Calculate, sunrise, time, in, the, UTC, timez...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18241</th>\n",
       "      <td>sffjunkie/astral</td>\n",
       "      <td>src/astral.py</td>\n",
       "      <td>https://github.com/sffjunkie/astral/blob/b0aa6...</td>\n",
       "      <td>def solar_noon_utc(self, date, longitude):\\n  ...</td>\n",
       "      <td>[def, solar_noon_utc, (, self, ,, date, ,, lon...</td>\n",
       "      <td>Calculate solar noon time in the UTC timezone....</td>\n",
       "      <td>[Calculate, solar, noon, time, in, the, UTC, t...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18242</th>\n",
       "      <td>sffjunkie/astral</td>\n",
       "      <td>src/astral.py</td>\n",
       "      <td>https://github.com/sffjunkie/astral/blob/b0aa6...</td>\n",
       "      <td>def sunset_utc(self, date, latitude, longitude...</td>\n",
       "      <td>[def, sunset_utc, (, self, ,, date, ,, latitud...</td>\n",
       "      <td>Calculate sunset time in the UTC timezone.\\n\\n...</td>\n",
       "      <td>[Calculate, sunset, time, in, the, UTC, timezo...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25974</th>\n",
       "      <td>bitcaster-io/bitcaster</td>\n",
       "      <td>src/bitcaster/config/environ.py</td>\n",
       "      <td>https://github.com/bitcaster-io/bitcaster/blob...</td>\n",
       "      <td>def get_value(self, var, cast=None, default=en...</td>\n",
       "      <td>[def, get_value, (, self, ,, var, ,, cast, =, ...</td>\n",
       "      <td>Return value for given environment variable.\\n...</td>\n",
       "      <td>[Return, value, for, given, environment, varia...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25975</th>\n",
       "      <td>bitcaster-io/bitcaster</td>\n",
       "      <td>src/bitcaster/utils/reflect.py</td>\n",
       "      <td>https://github.com/bitcaster-io/bitcaster/blob...</td>\n",
       "      <td>def fqn(o):\\n    \"\"\"Returns the fully qualifie...</td>\n",
       "      <td>[def, fqn, (, o, ), :, parts, =, [, ], if, isi...</td>\n",
       "      <td>Returns the fully qualified class name of an o...</td>\n",
       "      <td>[Returns, the, fully, qualified, class, name, ...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25976</th>\n",
       "      <td>bitcaster-io/bitcaster</td>\n",
       "      <td>src/bitcaster/otp.py</td>\n",
       "      <td>https://github.com/bitcaster-io/bitcaster/blob...</td>\n",
       "      <td>def get_otp(self, message_list):\\n        \"\"\"\\...</td>\n",
       "      <td>[def, get_otp, (, self, ,, message_list, ), :,...</td>\n",
       "      <td>Generates a url-safe base64 encoded encypted m...</td>\n",
       "      <td>[Generates, a, url, -, safe, base64, encoded, ...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25977</th>\n",
       "      <td>bitcaster-io/bitcaster</td>\n",
       "      <td>src/bitcaster/otp.py</td>\n",
       "      <td>https://github.com/bitcaster-io/bitcaster/blob...</td>\n",
       "      <td>def validate(self, cipher_text, max_timedelta=...</td>\n",
       "      <td>[def, validate, (, self, ,, cipher_text, ,, ma...</td>\n",
       "      <td>Will decrypt the url safe base64 encoded crypt...</td>\n",
       "      <td>[Will, decrypt, the, url, safe, base64, encode...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25978</th>\n",
       "      <td>bitcaster-io/bitcaster</td>\n",
       "      <td>src/bitcaster/utils/language.py</td>\n",
       "      <td>https://github.com/bitcaster-io/bitcaster/blob...</td>\n",
       "      <td>def get_attr(obj, attr, default=None):\\n    \"\"...</td>\n",
       "      <td>[def, get_attr, (, obj, ,, attr, ,, default, =...</td>\n",
       "      <td>Recursive get object's attribute. May use dot ...</td>\n",
       "      <td>[Recursive, get, object, s, attribute, ., May,...</td>\n",
       "      <td>python</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:49:20.288808Z",
     "start_time": "2024-11-05T04:49:16.668822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
   ],
   "id": "cb726c6766342856",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T04:49:20.842692Z",
     "start_time": "2024-11-05T04:49:20.337314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载分词器和模型\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ],
   "id": "6bbc133578085879",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:04:38.753551Z",
     "start_time": "2024-11-05T04:49:20.846684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm  # 导入 tqdm 进度条\n",
    "\n",
    "# 自定义数据集类\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        code = self.data.iloc[idx]['code']\n",
    "        inputs = self.tokenizer(code, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n",
    "        return inputs['input_ids'].squeeze(), inputs['attention_mask'].squeeze()\n",
    "\n",
    "\n",
    "# 手动定义一个掩码 token\n",
    "mask_token_id = tokenizer.convert_tokens_to_ids('<extra_id_0>')\n",
    "\n",
    "# 使用 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 数据加载\n",
    "train_dataset = CodeDataset(pretrain_data, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    # 使用 tqdm 显示进度条\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "        # 随机遮蔽部分 token\n",
    "        mask_idx = torch.rand(input_ids.shape).to(input_ids.device) < 0.15  # 随机屏蔽 15% 的 token\n",
    "        input_ids[mask_idx] = mask_token_id\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed. Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# 保存预训练模型\n",
    "model.save_pretrained('pretrained_if_model')\n",
    "tokenizer.save_pretrained('pretrained_if_tokenizer')\n"
   ],
   "id": "96c1356a12ae8d18",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/18750 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Epoch 1/3: 100%|██████████| 18750/18750 [1:05:31<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Loss: 0.26970973925014335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 18750/18750 [1:04:54<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Loss: 0.1827282580723365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 18750/18750 [1:04:51<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Loss: 0.181082252411445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('pretrained_if_tokenizer\\\\tokenizer_config.json',\n",
       " 'pretrained_if_tokenizer\\\\special_tokens_map.json',\n",
       " 'pretrained_if_tokenizer\\\\spiece.model',\n",
       " 'pretrained_if_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:56:45.184619Z",
     "start_time": "2024-11-05T08:04:39.766965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载微调数据集\n",
    "finetune_dataset = CodeDataset(train_finetune_data, tokenizer)\n",
    "finetune_loader = DataLoader(finetune_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(finetune_loader, desc=f\"Fine-tuning Epoch {epoch+1}/{epochs}\"):\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "        # 随机遮蔽部分 token\n",
    "        mask_idx = torch.rand(input_ids.shape).to(input_ids.device) < 0.15  # 随机屏蔽 15% 的 token\n",
    "        input_ids[mask_idx] = mask_token_id\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Fine-tuning Epoch {epoch + 1} completed. Loss: {epoch_loss/len(finetune_loader)}\")\n"
   ],
   "id": "93ebd1bd3a5d9bca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1/3: 100%|██████████| 5000/5000 [17:18<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 1 completed. Loss: 0.1785067981272936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 2/3: 100%|██████████| 5000/5000 [17:27<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 2 completed. Loss: 0.17839170552529396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 3/3: 100%|██████████| 5000/5000 [17:19<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning Epoch 3 completed. Loss: 0.17838816022798418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:57:28.315393Z",
     "start_time": "2024-11-05T08:56:46.136907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 验证模型\n",
    "valid_dataset = CodeDataset(valid_finetune_data, tokenizer)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(valid_loader, desc=\"Validating\"):\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        val_loss += outputs.loss.item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / len(valid_loader)}\")\n"
   ],
   "id": "b3505d8ba65baf0e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 625/625 [00:42<00:00, 14.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.07536070138423238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:58:11.162418Z",
     "start_time": "2024-11-05T08:57:29.314665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 测试模型\n",
    "test_dataset = CodeDataset(test_finetune_data, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids, attention_mask = batch\n",
    "        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        test_loss += outputs.loss.item()\n",
    "\n",
    "print(f\"Test Loss: {test_loss / len(test_loader)}\")\n"
   ],
   "id": "66e3ca10f12a4d70",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 625/625 [00:41<00:00, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.07977731139548123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:58:12.262714Z",
     "start_time": "2024-11-05T08:58:12.060988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存微调模型\n",
    "model.save_pretrained('finetuned_if_model')\n",
    "tokenizer.save_pretrained('finetuned_if_tokenizer')\n"
   ],
   "id": "d470e97c812cb0e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finetuned_if_tokenizer\\\\tokenizer_config.json',\n",
       " 'finetuned_if_tokenizer\\\\special_tokens_map.json',\n",
       " 'finetuned_if_tokenizer\\\\spiece.model',\n",
       " 'finetuned_if_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T08:58:14.873069Z",
     "start_time": "2024-11-05T08:58:13.188420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 随机选择一条原始代码样本\n",
    "sample_idx = torch.randint(0, len(test_finetune_data), (1,)).item()\n",
    "original_code = test_finetune_data.iloc[sample_idx]['code']\n",
    "\n",
    "# 对原始代码进行分词并通过模型生成预测\n",
    "inputs = tokenizer(original_code, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=512)\n",
    "    \n",
    "# 将模型生成的预测结果解码\n",
    "predicted_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 输出原始代码与模型生成的代码\n",
    "print(\"Original Code:\\n\", original_code)\n",
    "print(\"\\nPredicted Code:\\n\", predicted_code)\n"
   ],
   "id": "1267203302f3eee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Code:\n",
      " def start(self, initial_delay=0):\n",
      "        \"\"\"Wait for push updates from device.\n",
      "\n",
      "        Will throw NoAsyncListenerError if no listner has been set.\n",
      "        \"\"\"\n",
      "        if self.listener is None:\n",
      "            raise exceptions.NoAsyncListenerError\n",
      "        elif self._future is not None:\n",
      "            return None\n",
      "\n",
      "        # Always start with 0 to trigger an immediate response for the\n",
      "        # first request\n",
      "        self._atv.playstatus_revision = 0\n",
      "\n",
      "        # This for some reason fails on travis but not in other places.\n",
      "        # Why is that (same python version)?\n",
      "        # pylint: disable=deprecated-method\n",
      "        self._future = asyncio.ensure_future(\n",
      "            self._poller(initial_delay), loop=self._loop)\n",
      "        return self._future\n",
      "\n",
      "Predicted Code:\n",
      " def start(self, initial_delay=0): \"\"\"Wait for push updates from device. Will throw NoAsyncListenerError if no listner has been set. \"\"\" if self.listener is None: raise exceptions.NoAsyncListenerError elif self._future is not None: return None # Always start with 0 to trigger an immediate response for the # first request self._atv.playstatus_revision = 0 # This for some reason fails on travis but not in other places. # Why is that (same python version)? # pylint: disable=deprecated-method self._future = asyncio.ensure_future( self._poller(initial_delay), loop=self._loop) return self._future\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T09:25:09.652702Z",
     "start_time": "2024-11-05T09:23:39.207098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载提供的测试集\n",
    "provided_test_data = pd.read_csv('sample.csv')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# 定义生成 CSV 文件的函数\n",
    "def generate_testset_csv(test_data, input_col, target_col, csv_filename):\n",
    "    results = []\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "    \n",
    "    # 自定义数据集类\n",
    "    class CodeDataset(Dataset):\n",
    "        def __init__(self, data, tokenizer, max_length=512):\n",
    "            self.data = data\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            code = self.data.iloc[idx][input_col]\n",
    "            inputs = self.tokenizer(code, return_tensors='pt', padding='max_length', truncation=True, max_length=self.max_length)\n",
    "            return inputs['input_ids'].squeeze(), inputs['attention_mask'].squeeze()\n",
    "\n",
    "    test_dataset = CodeDataset(test_data, tokenizer)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    if_token_id = tokenizer.convert_tokens_to_ids(\"if\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(test_loader, desc=f\"Processing {csv_filename}\")):\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n",
    "\n",
    "            # 获取真实输入代码和期望的 if 条件\n",
    "            original_code = test_data.iloc[i][input_col]\n",
    "            expected_if_condition = \"if\" in test_data.iloc[i][target_col]\n",
    "\n",
    "            # 生成预测代码\n",
    "            outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=512, output_scores=True, return_dict_in_generate=True)\n",
    "            predicted_code = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "\n",
    "            # 检查预测结果是否包含 if 条件\n",
    "            predicted_if_condition = \"if\" in predicted_code\n",
    "\n",
    "            # 使用 logits 计算最高“if”置信度的概率得分\n",
    "            scores = outputs.scores  # 生成过程中的 logits\n",
    "            max_if_prob = 0\n",
    "            for score in scores:\n",
    "                probs = torch.softmax(score, dim=-1)\n",
    "                if_prob = probs[0, if_token_id].item()\n",
    "                max_if_prob = max(max_if_prob, if_prob)  # 使用最高的“if”概率\n",
    "\n",
    "            # 转换得分为0-100范围\n",
    "            prediction_score = max_if_prob * 100\n",
    "\n",
    "            # 记录是否预测正确\n",
    "            is_correct = expected_if_condition == predicted_if_condition\n",
    "\n",
    "            # 将每条记录存储到 results 列表\n",
    "            results.append({\n",
    "                \"Input provided to the model\": original_code,\n",
    "                \"Whether the prediction is correct (true/false)\": is_correct,\n",
    "                \"Expected if condition\": expected_if_condition,\n",
    "                \"Predicted if condition\": predicted_if_condition,\n",
    "                \"Prediction score (0-100)\": prediction_score\n",
    "            })\n",
    "\n",
    "    # 转换为 DataFrame 并保存为 CSV 文件\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "\n",
    "\n",
    "\n",
    "# 使用提供的测试集生成 provided-testset.csv\n",
    "generate_testset_csv(provided_test_data, 'input_method', 'target_block', 'provided-testset.csv')\n"
   ],
   "id": "23c1cda300829104",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing provided-testset.csv: 100%|██████████| 30/30 [01:30<00:00,  3.01s/it]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:02:39.436501Z",
     "start_time": "2024-11-05T09:25:09.659494Z"
    }
   },
   "cell_type": "code",
   "source": "generate_testset_csv(test_finetune_data, 'code', 'code', 'generated-testset.csv')\n",
   "id": "4067eac99a56b9f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing generated-testset.csv: 100%|██████████| 5000/5000 [2:37:29<00:00,  1.89s/it]  \n"
     ]
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
